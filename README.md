# data_lake
Build an ETL pipeline for a data lake hosted on S3. load data from S3, process the data into analytics tables using Spark, and load them back into S3. Deploy this Spark process on a cluster using AWS.
